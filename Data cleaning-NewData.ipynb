{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data = pd.read_excel('List_Songs-HIPPOP.xlsx')\n",
    "data = pd.read_csv('List_Songs-ROCKHIP_new.csv') #,lineterminator='\\n')\n",
    "#data = data[['Lyrics', 'Title', 'Year', 'Genre']][3000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Language</th>\n",
       "      <th>Year_decade</th>\n",
       "      <th>Hip Hop</th>\n",
       "      <th>Rock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4800</th>\n",
       "      <td>4800</td>\n",
       "      <td>[uh, uh, uh, bring, attention, dirty, watch, t...</td>\n",
       "      <td>#1</td>\n",
       "      <td>2002</td>\n",
       "      <td>Hip Hop</td>\n",
       "      <td>en</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4801</th>\n",
       "      <td>4801</td>\n",
       "      <td>[chorus, 2x):(mannie, fresh, niggas, buck, buc...</td>\n",
       "      <td>#1</td>\n",
       "      <td>2002</td>\n",
       "      <td>Hip Hop</td>\n",
       "      <td>en</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4802</th>\n",
       "      <td>4802</td>\n",
       "      <td>[rich, nice, want, understand, mackin, big, bu...</td>\n",
       "      <td>#1 Player</td>\n",
       "      <td>1995</td>\n",
       "      <td>Hip Hop</td>\n",
       "      <td>en</td>\n",
       "      <td>1990</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4803</th>\n",
       "      <td>4803</td>\n",
       "      <td>[nigga, stunt, come, f*ckin, car, nigga, belie...</td>\n",
       "      <td>#1 Stunna</td>\n",
       "      <td>2000</td>\n",
       "      <td>Hip Hop</td>\n",
       "      <td>en</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4804</th>\n",
       "      <td>4804</td>\n",
       "      <td>[girl, birthday, birthday, tonight, tonight, g...</td>\n",
       "      <td>#BDAY</td>\n",
       "      <td>2000</td>\n",
       "      <td>Hip Hop</td>\n",
       "      <td>en</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                             Lyrics  \\\n",
       "4800        4800  [uh, uh, uh, bring, attention, dirty, watch, t...   \n",
       "4801        4801  [chorus, 2x):(mannie, fresh, niggas, buck, buc...   \n",
       "4802        4802  [rich, nice, want, understand, mackin, big, bu...   \n",
       "4803        4803  [nigga, stunt, come, f*ckin, car, nigga, belie...   \n",
       "4804        4804  [girl, birthday, birthday, tonight, tonight, g...   \n",
       "\n",
       "          Title  Year    Genre Language  Year_decade  Hip Hop  Rock  \n",
       "4800         #1  2002  Hip Hop       en         2000        1     0  \n",
       "4801         #1  2002  Hip Hop       en         2000        1     0  \n",
       "4802  #1 Player  1995  Hip Hop       en         1990        1     0  \n",
       "4803  #1 Stunna  2000  Hip Hop       en         2000        1     0  \n",
       "4804      #BDAY  2000  Hip Hop       en         2000        1     0  "
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(data['Lyrics'].loc[(data['Genre'] == 'Reggae') & (data['Lyrics'] != 'NONE')].head(5))\n",
    "#print(data['Lyrics'].loc[(data['Genre'] == 'Hip Hop') & (data['Lyrics'] != 'NONE')].head(5))\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of the rows that are dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of songs 9600\n",
      "After removal of songs with no lyrics 6727\n",
      "Number of remaining songs that are in English 6103\n",
      "Number of songs that are in both genres (and thus removed twice) 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4800</th>\n",
       "      <td>Uh uh uh\\nI just gotta bring it to they attent...</td>\n",
       "      <td>#1</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4801</th>\n",
       "      <td>\\n\\nChorus (2x):(Mannie Fresh)\\nAll the nigga...</td>\n",
       "      <td>#1</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4802</th>\n",
       "      <td>[Rich Nice] What I want you to understand is...</td>\n",
       "      <td>#1 Player</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4803</th>\n",
       "      <td>Nigga can't out-stunt me when it come to these...</td>\n",
       "      <td>#1 Stunna</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4804</th>\n",
       "      <td>Girl it's your birthday (birthday) in here (in...</td>\n",
       "      <td>#BDAY</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4805</th>\n",
       "      <td>Grind mode grind mode bitch I'm on grind mode\\...</td>\n",
       "      <td>#Grindmode</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4807</th>\n",
       "      <td>S'all you got?\\nS'all you got?\\nThat's all you...</td>\n",
       "      <td>#STUPiDFACEDD</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4808</th>\n",
       "      <td>Big man! When I talk hear weh yuh fi do?\\nShut...</td>\n",
       "      <td>#Twerkit</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4809</th>\n",
       "      <td>People killin' people dyin' Children hurtin' I...</td>\n",
       "      <td>#WHERESTHELOVE</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4810</th>\n",
       "      <td>Rich girl and you've come to far 'cause you kn...</td>\n",
       "      <td>$$$ Girlz</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4813</th>\n",
       "      <td>Uh uh uh You ready B? Let's go get 'em  Look f...</td>\n",
       "      <td>'03 Bonnie &amp; Clyde</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4814</th>\n",
       "      <td>Uh uh uh You ready B? Let's go get 'em  Look f...</td>\n",
       "      <td>'03 Bonnie &amp; Clyde</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4815</th>\n",
       "      <td>Next time on Poppy Street  Good mornin' hope y...</td>\n",
       "      <td>'06</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4816</th>\n",
       "      <td>Next time on Poppy Street\\n\\nGood mornin' hope...</td>\n",
       "      <td>'06</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4817</th>\n",
       "      <td>Just the two of us  C'mon hai-hai we goin' to ...</td>\n",
       "      <td>'97 Bonnie &amp; Clyde</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4818</th>\n",
       "      <td>Just the two of us  C'mon hai-hai we goin' to ...</td>\n",
       "      <td>'97 Bonnie &amp; Clyde</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4819</th>\n",
       "      <td>Just the two of us  C'mon hai-hai we goin' to ...</td>\n",
       "      <td>'97 Bonnie &amp; Clyde</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4820</th>\n",
       "      <td>Just the two of us  C'mon hai-hai we goin' to ...</td>\n",
       "      <td>'97 Bonnie &amp; Clyde</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4822</th>\n",
       "      <td>Don't be scared of this\\nTerror Sqaud\\nDon't b...</td>\n",
       "      <td>'99 Live</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4824</th>\n",
       "      <td>[Master P] Uggggghhhhhh its time for the natio...</td>\n",
       "      <td>'Bout It Bout It II\"</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4825</th>\n",
       "      <td>Girl I been longin' to make love to you\\nAnd n...</td>\n",
       "      <td>'Bout It, 'Bout It</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4826</th>\n",
       "      <td>It's 'bout that time\\nWoo yeah aha aha you kno...</td>\n",
       "      <td>'Bout That Time</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4827</th>\n",
       "      <td>'Cause sometimes you just feel tired you feel ...</td>\n",
       "      <td>'Till I Collapse</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4829</th>\n",
       "      <td>Look into my eyes You will see what you mean t...</td>\n",
       "      <td>(Everything I Do) I Do It for You</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4830</th>\n",
       "      <td>It took a keys and Jay-Z to get this city popp...</td>\n",
       "      <td>(Ha Ha) Slow Down</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4833</th>\n",
       "      <td>Hmm I'm going down down baby yo street in a Ra...</td>\n",
       "      <td>(Hot S**t) Country Grammar</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4834</th>\n",
       "      <td>I got the first flight out when I finished up ...</td>\n",
       "      <td>(How Could You) Bring Him Home</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4835</th>\n",
       "      <td>[B-Real talking] A lot of a sharks out there t...</td>\n",
       "      <td>(Rock) Superstar</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4836</th>\n",
       "      <td>So you want to be a rap superstar and live lar...</td>\n",
       "      <td>(Rock) Superstar</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4837</th>\n",
       "      <td>Little rump shaker she can really shake and ba...</td>\n",
       "      <td>(She's Got) Skillz</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4891</th>\n",
       "      <td>I made a promise to my momma That I'll bless h...</td>\n",
       "      <td>100 Grandkids</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4892</th>\n",
       "      <td>KRS and Melodie live together with D-Nice and ...</td>\n",
       "      <td>100 Guns</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>And why do we call ourselves niggaz 4 life Cau...</td>\n",
       "      <td>100 Miles and Runnin'</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>Dis for da hood Dis for da ghetto Dis for all ...</td>\n",
       "      <td>100 Million</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>Man: Yo What up D? Huh? You bought that from T...</td>\n",
       "      <td>100 Rounds</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>Ooh Puerto Rico  Toma  [Chorus] El dia de mi s...</td>\n",
       "      <td>100%</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>You used to the sound of a heart that's breaki...</td>\n",
       "      <td>101</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4901</th>\n",
       "      <td>12\\n\\n\"Wake...\\nRevenge is mine\\n12 people wil...</td>\n",
       "      <td>12</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4902</th>\n",
       "      <td>It's ya boi M.H.\\nJoe Budden\\n(Joey)\\nWe at it...</td>\n",
       "      <td>12 O'Clock</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4903</th>\n",
       "      <td>It's ya boi M.H. Joe Budden (Joey) We at it ag...</td>\n",
       "      <td>12 O'Clock</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4904</th>\n",
       "      <td>Yo I got 12 things to say And 12 ways of sayin...</td>\n",
       "      <td>12 Play</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4908</th>\n",
       "      <td>I walked in the place very big space  Every ki...</td>\n",
       "      <td>13 and Good</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4910</th>\n",
       "      <td>(18 dummy)\\nYeah\\n(We go 18 dummy)\\nWhat they ...</td>\n",
       "      <td>18 Dummy</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4911</th>\n",
       "      <td>[B.G.] I'm a young nigga go by tha name B.G. D...</td>\n",
       "      <td>187</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4912</th>\n",
       "      <td>I'm tryin' to keep my aces and my deuces all t...</td>\n",
       "      <td>187 He Wrote</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4913</th>\n",
       "      <td>Coolin' on the corner with the cellular phone ...</td>\n",
       "      <td>187 Proof</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4915</th>\n",
       "      <td>Music that we choose Music that we choose Musi...</td>\n",
       "      <td>19-2000 [Soulchild Remix]</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4917</th>\n",
       "      <td>The world is spinnin' too fast I'm buyin' that...</td>\n",
       "      <td>19-2000 [Soulchild Remix]</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4918</th>\n",
       "      <td>It's the music that we choose It's the music t...</td>\n",
       "      <td>19-2000 [Soulchild Remix]</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4919</th>\n",
       "      <td>I don't follow rules and they don't like that ...</td>\n",
       "      <td>1942</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4920</th>\n",
       "      <td>Istanbul.  I'm sure now.   Istanbul.  I don't ...</td>\n",
       "      <td>1976</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4923</th>\n",
       "      <td>[Chorus] Kill 'em all  Kill 'em all Kill 'em a...</td>\n",
       "      <td>1990-Sick</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4924</th>\n",
       "      <td>[Chorus] Kill 'em all  Kill 'em all Kill 'em a...</td>\n",
       "      <td>1990-Sick (Kill 'Em All)</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4925</th>\n",
       "      <td>Oh là là là flirting with a cool french dude n...</td>\n",
       "      <td>1991</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4926</th>\n",
       "      <td>You on point phife?  Once again tip You on poi...</td>\n",
       "      <td>1nce Again</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4927</th>\n",
       "      <td>You on point Phife? Once Again Tip You on poin...</td>\n",
       "      <td>1nce Again</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4929</th>\n",
       "      <td>WRONG!!  COLLIPARK!!! YEAHR!!! HAAAH!  What th...</td>\n",
       "      <td>1st Booty on Duty</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4930</th>\n",
       "      <td>Yah Swizzop It's Gucci Mike Will  I'm hearing ...</td>\n",
       "      <td>1st Day Out Tha Feds</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4931</th>\n",
       "      <td>1st Thing First why'all niggas better recogniz...</td>\n",
       "      <td>1st Thing First</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4932</th>\n",
       "      <td>[Chorus x 2] It ain't nothing like the first t...</td>\n",
       "      <td>1st Time</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Lyrics  \\\n",
       "4800  Uh uh uh\\nI just gotta bring it to they attent...   \n",
       "4801   \\n\\nChorus (2x):(Mannie Fresh)\\nAll the nigga...   \n",
       "4802    [Rich Nice] What I want you to understand is...   \n",
       "4803  Nigga can't out-stunt me when it come to these...   \n",
       "4804  Girl it's your birthday (birthday) in here (in...   \n",
       "4805  Grind mode grind mode bitch I'm on grind mode\\...   \n",
       "4807  S'all you got?\\nS'all you got?\\nThat's all you...   \n",
       "4808  Big man! When I talk hear weh yuh fi do?\\nShut...   \n",
       "4809  People killin' people dyin' Children hurtin' I...   \n",
       "4810  Rich girl and you've come to far 'cause you kn...   \n",
       "4813  Uh uh uh You ready B? Let's go get 'em  Look f...   \n",
       "4814  Uh uh uh You ready B? Let's go get 'em  Look f...   \n",
       "4815  Next time on Poppy Street  Good mornin' hope y...   \n",
       "4816  Next time on Poppy Street\\n\\nGood mornin' hope...   \n",
       "4817  Just the two of us  C'mon hai-hai we goin' to ...   \n",
       "4818  Just the two of us  C'mon hai-hai we goin' to ...   \n",
       "4819  Just the two of us  C'mon hai-hai we goin' to ...   \n",
       "4820  Just the two of us  C'mon hai-hai we goin' to ...   \n",
       "4822  Don't be scared of this\\nTerror Sqaud\\nDon't b...   \n",
       "4824  [Master P] Uggggghhhhhh its time for the natio...   \n",
       "4825  Girl I been longin' to make love to you\\nAnd n...   \n",
       "4826  It's 'bout that time\\nWoo yeah aha aha you kno...   \n",
       "4827  'Cause sometimes you just feel tired you feel ...   \n",
       "4829  Look into my eyes You will see what you mean t...   \n",
       "4830  It took a keys and Jay-Z to get this city popp...   \n",
       "4833  Hmm I'm going down down baby yo street in a Ra...   \n",
       "4834  I got the first flight out when I finished up ...   \n",
       "4835  [B-Real talking] A lot of a sharks out there t...   \n",
       "4836  So you want to be a rap superstar and live lar...   \n",
       "4837  Little rump shaker she can really shake and ba...   \n",
       "...                                                 ...   \n",
       "4891  I made a promise to my momma That I'll bless h...   \n",
       "4892  KRS and Melodie live together with D-Nice and ...   \n",
       "4893  And why do we call ourselves niggaz 4 life Cau...   \n",
       "4894  Dis for da hood Dis for da ghetto Dis for all ...   \n",
       "4895  Man: Yo What up D? Huh? You bought that from T...   \n",
       "4896  Ooh Puerto Rico  Toma  [Chorus] El dia de mi s...   \n",
       "4897  You used to the sound of a heart that's breaki...   \n",
       "4901  12\\n\\n\"Wake...\\nRevenge is mine\\n12 people wil...   \n",
       "4902  It's ya boi M.H.\\nJoe Budden\\n(Joey)\\nWe at it...   \n",
       "4903  It's ya boi M.H. Joe Budden (Joey) We at it ag...   \n",
       "4904  Yo I got 12 things to say And 12 ways of sayin...   \n",
       "4908  I walked in the place very big space  Every ki...   \n",
       "4910  (18 dummy)\\nYeah\\n(We go 18 dummy)\\nWhat they ...   \n",
       "4911  [B.G.] I'm a young nigga go by tha name B.G. D...   \n",
       "4912  I'm tryin' to keep my aces and my deuces all t...   \n",
       "4913  Coolin' on the corner with the cellular phone ...   \n",
       "4915  Music that we choose Music that we choose Musi...   \n",
       "4917  The world is spinnin' too fast I'm buyin' that...   \n",
       "4918  It's the music that we choose It's the music t...   \n",
       "4919  I don't follow rules and they don't like that ...   \n",
       "4920  Istanbul.  I'm sure now.   Istanbul.  I don't ...   \n",
       "4923  [Chorus] Kill 'em all  Kill 'em all Kill 'em a...   \n",
       "4924  [Chorus] Kill 'em all  Kill 'em all Kill 'em a...   \n",
       "4925  Oh là là là flirting with a cool french dude n...   \n",
       "4926  You on point phife?  Once again tip You on poi...   \n",
       "4927  You on point Phife? Once Again Tip You on poin...   \n",
       "4929  WRONG!!  COLLIPARK!!! YEAHR!!! HAAAH!  What th...   \n",
       "4930  Yah Swizzop It's Gucci Mike Will  I'm hearing ...   \n",
       "4931  1st Thing First why'all niggas better recogniz...   \n",
       "4932  [Chorus x 2] It ain't nothing like the first t...   \n",
       "\n",
       "                                  Title  Year  \n",
       "4800                                 #1  2002  \n",
       "4801                                 #1  2002  \n",
       "4802                          #1 Player  1995  \n",
       "4803                          #1 Stunna  2000  \n",
       "4804                              #BDAY  NONE  \n",
       "4805                         #Grindmode  NONE  \n",
       "4807                      #STUPiDFACEDD  2011  \n",
       "4808                           #Twerkit  NONE  \n",
       "4809                     #WHERESTHELOVE  2016  \n",
       "4810                          $$$ Girlz  2004  \n",
       "4813                 '03 Bonnie & Clyde  2002  \n",
       "4814                 '03 Bonnie & Clyde  2003  \n",
       "4815                                '06  2015  \n",
       "4816                                '06  2015  \n",
       "4817                 '97 Bonnie & Clyde  1999  \n",
       "4818                 '97 Bonnie & Clyde  1999  \n",
       "4819                 '97 Bonnie & Clyde  2000  \n",
       "4820                 '97 Bonnie & Clyde  1999  \n",
       "4822                           '99 Live  1999  \n",
       "4824               'Bout It Bout It II\"  1996  \n",
       "4825                 'Bout It, 'Bout It  1998  \n",
       "4826                    'Bout That Time  2002  \n",
       "4827                   'Till I Collapse  2002  \n",
       "4829  (Everything I Do) I Do It for You  1998  \n",
       "4830                  (Ha Ha) Slow Down  2010  \n",
       "4833         (Hot S**t) Country Grammar  2000  \n",
       "4834     (How Could You) Bring Him Home  2006  \n",
       "4835                   (Rock) Superstar  2000  \n",
       "4836                   (Rock) Superstar  2000  \n",
       "4837                 (She's Got) Skillz  1994  \n",
       "...                                 ...   ...  \n",
       "4891                      100 Grandkids  NONE  \n",
       "4892                           100 Guns  1990  \n",
       "4893              100 Miles and Runnin'  2006  \n",
       "4894                        100 Million  2007  \n",
       "4895                         100 Rounds  1999  \n",
       "4896                               100%  2000  \n",
       "4897                                101  2012  \n",
       "4901                                 12  1995  \n",
       "4902                         12 O'Clock  2005  \n",
       "4903                         12 O'Clock  2005  \n",
       "4904                            12 Play  1993  \n",
       "4908                        13 and Good  1992  \n",
       "4910                           18 Dummy  2007  \n",
       "4911                                187  2000  \n",
       "4912                       187 He Wrote  1993  \n",
       "4913                          187 Proof  1998  \n",
       "4915          19-2000 [Soulchild Remix]  2001  \n",
       "4917          19-2000 [Soulchild Remix]  2011  \n",
       "4918          19-2000 [Soulchild Remix]  2002  \n",
       "4919                               1942  2018  \n",
       "4920                               1976  2004  \n",
       "4923                          1990-Sick  2010  \n",
       "4924           1990-Sick (Kill 'Em All)  1998  \n",
       "4925                               1991  2012  \n",
       "4926                         1nce Again  1996  \n",
       "4927                         1nce Again  1996  \n",
       "4929                  1st Booty on Duty  2006  \n",
       "4930               1st Day Out Tha Feds  2016  \n",
       "4931                    1st Thing First  1998  \n",
       "4932                           1st Time  2006  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print('Initial number of songs', len(data))\n",
    "\n",
    "data1 = data[data.Lyrics != 'NONE']\n",
    "\n",
    "print('After removal of songs with no lyrics' , len(data1))\n",
    "\n",
    "data2 = data1.loc[data1['Lyrics'].apply(detect) == 'en']\n",
    "print('Number of remaining songs that are in English', len(data2))\n",
    " \n",
    "# Split into two dataframes by genre    \n",
    "pop_df = data2[['Lyrics','Title','Year']].loc[data2['Genre'] == 'Reggae']\n",
    "hiphop_df = data2[['Lyrics','Title','Year']].loc[data2['Genre'] == 'Hip Hop']\n",
    "\n",
    "# Inner join to get the songs that are in both\n",
    "df12 = pd.merge(hiphop_df,pop_df, on=['Title','Year','Lyrics'], how='inner')     #extract common rows with merge\n",
    "final_hiphop = hiphop_df[~hiphop_df['Lyrics'].isin(df12['Lyrics'])]\n",
    "final_pop = pop_df[~pop_df['Lyrics'].isin(df12['Lyrics'])]\n",
    "\n",
    "print('Number of songs that are in both genres (and thus removed twice)',len(df12))\n",
    "\n",
    "final_hiphop.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data tidying function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import string\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "\n",
    "# Create our list of punctuation marks\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# Create our list of stopwords\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "# Load English tokenizer\n",
    "parser = English()\n",
    "\n",
    "# Creating our tokenizer function\n",
    "def spacy_tokenizer(sentence):\n",
    "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
    "    mytokens = parser(sentence)\n",
    "\n",
    "    # Lemmatizing each token and converting each token into lowercase\n",
    "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "\n",
    "    # Removing stop words\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
    "\n",
    "    # return preprocessed list of tokens\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidy_data(df):\n",
    "    start_len = len(df)\n",
    "    ### Function that takes as input the dataframe and outputs the clean dataframe \n",
    "    \n",
    "    # Drop rows where Lyrics = None\n",
    "    df = df[df.Lyrics != 'NONE']\n",
    "    \n",
    "    # Detect language and drop all rows where language is not English\n",
    "    df['Language'] = df['Lyrics'].apply(detect)\n",
    "    df = df.loc[df['Language'] == 'en']\n",
    "    #df = df.drop(['Language'], axis=1)\n",
    "    \n",
    "    print('Number of songs before dropping duplicates', len(df)) \n",
    "    \n",
    "    # Find lyrics that are in both genres and remove them both \n",
    "    # Split into two dataframes by genre    \n",
    "    pop_df = data2[['Lyrics','Title','Year']].loc[data2['Genre'] == 'Pop']\n",
    "    hiphop_df = data2[['Lyrics','Title','Year']].loc[data2['Genre'] == 'Hip Hop']\n",
    "\n",
    "    # Inner join to get the songs that are in both\n",
    "    df12 = pd.merge(hiphop_df,pop_df, on=['Title','Year','Lyrics'], how='inner')     #extract common rows with merge\n",
    "    final_hiphop = hiphop_df[~hiphop_df['Lyrics'].isin(df12['Lyrics'])]\n",
    "    final_pop = pop_df[~pop_df['Lyrics'].isin(df12['Lyrics'])]\n",
    "    \n",
    "    #Combine\n",
    "    hiphop_pop_concat = pd.concat([final_hiphop,final_pop])\n",
    "    \n",
    "    #Put 'Genres' back on\n",
    "    final_df = pd.merge(hiphop_pop_concat,pd.DataFrame(df[['Lyrics','Genre']]),on='Lyrics',how='left')\n",
    "    \n",
    "    #df = df.drop_duplicates(subset=['Lyrics', 'Title', 'Year'], keep=False)\n",
    "    #print('Number of songs after dropping genre duplicates', len(df)) \n",
    "    final_df = df.drop_duplicates()\n",
    "    print('Number of songs after dropping actual duplicates', len(final_df))\n",
    "    \n",
    "    #Apply tokenizer\n",
    "    final_df['Lyrics'] = final_df['Lyrics'].apply(spacy_tokenizer)\n",
    "    \n",
    "    # Remove None values create decade column and \n",
    "    final_df['Year'] = final_df['Year'].replace('NONE',None)\n",
    "    final_df['Title'] = final_df['Title'].replace('NONE',None)\n",
    "    final_df['Lyrics'] = final_df['Lyrics'].replace('\\n',' ')\n",
    "    final_df['Year_decade'] = pd.to_numeric(final_df['Year'])//10*10\n",
    "  \n",
    "    # Get genre dummies \n",
    "    dummy=pd.get_dummies(final_df[\"Genre\"])\n",
    "    final_df = pd.concat([final_df, dummy], axis=1)\n",
    "    \n",
    "    tidied_len = len(final_df)\n",
    "    print('Function removed', start_len - tidied_len, 'out of', start_len, 'rows')\n",
    "    \n",
    "    return final_df #(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of songs before dropping duplicates 6103\n",
      "Number of songs after dropping actual duplicates 6103\n",
      "Function removed 3497 out of 9600 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Language</th>\n",
       "      <th>Year_decade</th>\n",
       "      <th>Hip Hop</th>\n",
       "      <th>Rock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[wait, patiently, lord, incline, hear, cry, br...</td>\n",
       "      <td>\"40\"</td>\n",
       "      <td>1991</td>\n",
       "      <td>Rock</td>\n",
       "      <td>en</td>\n",
       "      <td>1990</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[wait, patiently, lord, incline, hear, cry, br...</td>\n",
       "      <td>\"40\"</td>\n",
       "      <td>1987</td>\n",
       "      <td>Rock</td>\n",
       "      <td>en</td>\n",
       "      <td>1980</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[sing, 40, waited, patiently, lord, inclined, ...</td>\n",
       "      <td>\"40\"</td>\n",
       "      <td>1983</td>\n",
       "      <td>Rock</td>\n",
       "      <td>en</td>\n",
       "      <td>1980</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>[hand, look, 'em, shake, song, repeat, drop, n...</td>\n",
       "      <td>\"45\"</td>\n",
       "      <td>2012</td>\n",
       "      <td>Rock</td>\n",
       "      <td>en</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>[love, line, straight, narrow, love, try, true...</td>\n",
       "      <td>\"5150\"</td>\n",
       "      <td>1986</td>\n",
       "      <td>Rock</td>\n",
       "      <td>en</td>\n",
       "      <td>1980</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>[street, pave, blood, cataclysmic, overtone, f...</td>\n",
       "      <td>\"A\" Bomb in Wardour Street</td>\n",
       "      <td>2016</td>\n",
       "      <td>Rock</td>\n",
       "      <td>en</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>[life, strange, know, head, new, worth, live, ...</td>\n",
       "      <td>\"D\" Train</td>\n",
       "      <td>1989</td>\n",
       "      <td>Rock</td>\n",
       "      <td>en</td>\n",
       "      <td>1980</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>[eat, sleep, breathe, anymore, sleep, count, s...</td>\n",
       "      <td>\"Do You Sleep\"</td>\n",
       "      <td>2008</td>\n",
       "      <td>Rock</td>\n",
       "      <td>en</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>[king, queen, drive, away, beat, day, hero, da...</td>\n",
       "      <td>\"Heroes\"</td>\n",
       "      <td>1978</td>\n",
       "      <td>Rock</td>\n",
       "      <td>en</td>\n",
       "      <td>1970</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>[king, queen, drive, away, beat, day, hero, da...</td>\n",
       "      <td>\"Heroes\"</td>\n",
       "      <td>1993</td>\n",
       "      <td>Rock</td>\n",
       "      <td>en</td>\n",
       "      <td>1990</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                             Lyrics  \\\n",
       "2            2  [wait, patiently, lord, incline, hear, cry, br...   \n",
       "3            3  [wait, patiently, lord, incline, hear, cry, br...   \n",
       "4            4  [sing, 40, waited, patiently, lord, inclined, ...   \n",
       "8            8  [hand, look, 'em, shake, song, repeat, drop, n...   \n",
       "9            9  [love, line, straight, narrow, love, try, true...   \n",
       "14          14  [street, pave, blood, cataclysmic, overtone, f...   \n",
       "16          16  [life, strange, know, head, new, worth, live, ...   \n",
       "17          17  [eat, sleep, breathe, anymore, sleep, count, s...   \n",
       "18          18  [king, queen, drive, away, beat, day, hero, da...   \n",
       "19          19  [king, queen, drive, away, beat, day, hero, da...   \n",
       "\n",
       "                         Title  Year Genre Language  Year_decade  Hip Hop  \\\n",
       "2                         \"40\"  1991  Rock       en         1990        0   \n",
       "3                         \"40\"  1987  Rock       en         1980        0   \n",
       "4                         \"40\"  1983  Rock       en         1980        0   \n",
       "8                         \"45\"  2012  Rock       en         2010        0   \n",
       "9                       \"5150\"  1986  Rock       en         1980        0   \n",
       "14  \"A\" Bomb in Wardour Street  2016  Rock       en         2010        0   \n",
       "16                   \"D\" Train  1989  Rock       en         1980        0   \n",
       "17              \"Do You Sleep\"  2008  Rock       en         2000        0   \n",
       "18                    \"Heroes\"  1978  Rock       en         1970        0   \n",
       "19                    \"Heroes\"  1993  Rock       en         1990        0   \n",
       "\n",
       "    Rock  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  \n",
       "8      1  \n",
       "9      1  \n",
       "14     1  \n",
       "16     1  \n",
       "17     1  \n",
       "18     1  \n",
       "19     1  "
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = tidy_data(data)\n",
    "data.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2823"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.loc[data['Genre'] == 'Hip Hop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2823"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.loc[data['Genre'] == 'Rock'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2823\n",
      "5646\n"
     ]
    }
   ],
   "source": [
    "# Create dataframe with equal amounts of each of the variables. \n",
    "\n",
    "\n",
    "#Split into dataframe pr genre \n",
    "hiphop_df = data.loc[data['Genre'] == 'Hip Hop']\n",
    "rock_df = data.loc[data['Genre'] == 'Rock']\n",
    "\n",
    "#Get minimum number of rows from the two \n",
    "min_rows = min(len(hiphop_df),len(rock_df))\n",
    "\n",
    "#Cut dataframes so they are both as long as the smallest one \n",
    "hiphop_df = hiphop_df[:min_rows]\n",
    "rock_df = rock_df[:min_rows]\n",
    "\n",
    "#Put them back together \n",
    "data = pd.concat([hiphop_df,rock_df])\n",
    "assert len(data) == 2*min_rows\n",
    "print(min_rows)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(r'20190827 - TidiedData.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas: \n",
    "- Do we swear more now than before? \n",
    "- Do newer songs use more or less disrespectful language towards women? \n",
    "- Which genres swear more? (obvious...) \n",
    "\n",
    "Calculate avg number of swear words per song.\n",
    "- Get list of swear words \n",
    "- Count how many swear words in each song - store number in new column \n",
    "- avg(number_of_swearwords) group by year, genre \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('20190827 - TidiedData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Year'].replace('NONE',None, inplace=True)\n",
    "data['Year_decade'] = pd.to_numeric(data['Year'])//10*10\n",
    "#data.loc[data['Year'] == 'NONE'] #['Year'].replace('NONE',None,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list of swear words\n",
    "profanity_url = 'http://www.bannedwordlist.com/lists/swearWords.txt'\n",
    "\n",
    "import requests\n",
    "\n",
    "profanity = requests.get(profanity_url).text\n",
    "profanity = set(profanity.split('\\r\\n'))\n",
    "\n",
    "#input extra swear words\n",
    "extras = {'f*ck','f**k','f*cked','f*ckin','f*cking','nigga', 'niggas', 'b*tch', 'bitches', 'b*tches'}\n",
    "\n",
    "#union the two sets \n",
    "prof = profanity.union(extras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profanity_check(document, dictionary):\n",
    "    # Function that counts how many swear words are in a song. Input one tokenized song, output is the count. \n",
    "    list_match = []\n",
    "    \n",
    "    for word in document: \n",
    "        if word in dictionary:\n",
    "             list_match.append(word)\n",
    "\n",
    "    return len(list_match) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print(data['Lyrics'].loc[data['Genre'] == 'Rock'])\n",
    "\n",
    "#string = \n",
    "#print(data['Lyrics'][10434])\n",
    "#print(string)\n",
    "#profanity_check(string,prof)\n",
    "\n",
    "# Apply profanity check function to Lyrics \n",
    "data['Profanity_count'] = data['Lyrics'].apply(profanity_check, args=[prof])\n",
    "\n",
    "#data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head()\n",
    "data['Year_decade'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = pd.DataFrame(data.groupby(['Year_decade', 'Genre']).mean()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Only continue with songs from 1980's and forth\n",
    "g1 = g1.loc[g1['Year_decade'] >= 1980]\n",
    "\n",
    "# Create bar plot \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "g1 = g1[['Genre', 'Year_decade', 'Profanity_count']]\n",
    "\n",
    "ax = g1.pivot('Year_decade','Genre',  'Profanity_count').plot(kind='bar')\n",
    "#ax.set_title('Average number of swear words in a song \\n by year and genre')\n",
    "plt.ylabel('Avg number of swearwords per song')\n",
    "plt.xlabel(None)\n",
    "plt.xticks(rotation='horizontal')\n",
    "plt.yticks(np.arange(0, 20, step=5))\n",
    "\n",
    "plt.legend(loc=1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most used words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_per_song(list_of_strings, words_dictionary):\n",
    "    for i in range(len(list_of_strings)): \n",
    "    \n",
    "        if list_of_strings[i] in words_dictionary: \n",
    "            #print(word)\n",
    "            words_dictionary[list_of_strings[i]] += 1\n",
    "        else:\n",
    "            words_dictionary[list_of_strings[i]] = 1\n",
    "            \n",
    "    return words_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hiphop_df = data1.loc[data1['Genre'] == 'Hip Hop']\n",
    "pop_df = data1.loc[data1['Genre'] == 'Pop']\n",
    "rock_df = data1.loc[data1['Genre'] == 'Rock']\n",
    "\n",
    "\n",
    "hiphop = {}\n",
    "word_count_hip = hiphop_df['Lyrics'].apply(count_per_song, args=[hiphop])\n",
    "hiphop\n",
    "\n",
    "rock = {}\n",
    "word_count_rock = rock_df['Lyrics'].apply(count_per_song, args=[rock])\n",
    "rock\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lr}\n",
      "\\toprule\n",
      "{} &  Count \\\\\n",
      "\\midrule\n",
      "like  &   1498 \\\\\n",
      "know  &   1305 \\\\\n",
      "want  &    828 \\\\\n",
      "love  &    828 \\\\\n",
      "nigga &    765 \\\\\n",
      "baby  &    685 \\\\\n",
      "time  &    589 \\\\\n",
      "let   &    580 \\\\\n",
      "man   &    527 \\\\\n",
      "come  &    523 \\\\\n",
      "yes   &    516 \\\\\n",
      "oh    &    513 \\\\\n",
      "way   &    512 \\\\\n",
      "girl  &    499 \\\\\n",
      "tell  &    480 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wordcount_hiphop_df = pd.DataFrame.from_dict(hiphop, orient='index')\n",
    "wordcount_hiphop_df.columns = ['Count']\n",
    "\n",
    "wordcount_rock_df = pd.DataFrame.from_dict(rock, orient='index')\n",
    "wordcount_rock_df.columns = ['Count']\n",
    "\n",
    "\n",
    "hiphop_sorted = wordcount_hiphop_df.sort_values(by=['Count'],ascending=False)\n",
    "rock_sorted = wordcount_rock_df.sort_values(by=['Count'],ascending=False)\n",
    "\n",
    "\n",
    "hiphop_sorted.head(15)\n",
    "rock_sorted.head(15)\n",
    "\n",
    "\n",
    "\n",
    "print(hiphop_sorted.head(15).to_latex())\n",
    "print(rock_sorted.head(15).to_latex())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk.util import ngrams \n",
    "\n",
    "\n",
    "#string_list = data['Lyrics'][100]\n",
    "\n",
    "#text = \"the quick person did not realize his speed and the quick person bumped \"\n",
    "#n_gram = 2\n",
    "#bigram = Counter(ngrams(string_list, n_gram))\n",
    "\n",
    "\n",
    "#bigram_df = pd.DataFrame.from_dict(bigram, orient='index')\n",
    "#bigram_df.head(20)\n",
    "#bigram_df.columns = ['Count']\n",
    "\n",
    "\n",
    "\n",
    "#bigram_sorted = bigram_df.sort_values(by=['Count'],ascending=False)\n",
    "\n",
    "#bigram_sorted.head(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = \"the quick person did not realize his speed and the quick person bumped \"\n",
    "#n_gram = 2\n",
    "\n",
    "#Counter(ngrams(text.split(), n_gram))\n",
    "\n",
    "\n",
    "#hiphop = {}\n",
    "#word_count_hip = hiphop_df['Lyrics'].apply(count_per_song, args=[hiphop])\n",
    "#hiphop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_dictionary = Counter()\n",
    "\n",
    "def bigram_song(list_of_strings, total_dictionary = Counter()):\n",
    "    n_gram = 2\n",
    "\n",
    "    song_dictionary = Counter(ngrams(list_of_strings, n_gram))\n",
    "    \n",
    "    total_dictionary += song_dictionary\n",
    "    \n",
    "    return total_dictionary  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6714</th>\n",
       "      <td>(big, boy)</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13362</th>\n",
       "      <td>(lo, lo)</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>(know, know)</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>(oh, oh)</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3553</th>\n",
       "      <td>(yes, yes)</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>(da, da)</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6044</th>\n",
       "      <td>(want, want)</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3149</th>\n",
       "      <td>(love, love)</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30223</th>\n",
       "      <td>(ay, ay)</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5473</th>\n",
       "      <td>(la, la)</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4155</th>\n",
       "      <td>(let, know)</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8031</th>\n",
       "      <td>(live, life)</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>(uh, uh)</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>(baby, baby)</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3774</th>\n",
       "      <td>(uh, huh)</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10300</th>\n",
       "      <td>(alright, alright)</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11087</th>\n",
       "      <td>(oh, fall)</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>(hey, hey)</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24371</th>\n",
       "      <td>(gon, alright)</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20241</th>\n",
       "      <td>(way, turnt)</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   bigram  Count\n",
       "6714           (big, boy)    318\n",
       "13362            (lo, lo)    282\n",
       "430          (know, know)    262\n",
       "1273             (oh, oh)    256\n",
       "3553           (yes, yes)    256\n",
       "643              (da, da)    186\n",
       "6044         (want, want)    182\n",
       "3149         (love, love)    176\n",
       "30223            (ay, ay)    174\n",
       "5473             (la, la)    166\n",
       "4155          (let, know)    164\n",
       "8031         (live, life)    158\n",
       "1305             (uh, uh)    142\n",
       "1362         (baby, baby)    130\n",
       "3774            (uh, huh)    128\n",
       "10300  (alright, alright)    124\n",
       "11087          (oh, fall)    120\n",
       "1345           (hey, hey)    114\n",
       "24371      (gon, alright)    110\n",
       "20241        (way, turnt)    104"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "bigram_hip = hiphop_df['Lyrics'].apply(bigram_song) #, args = [total_dictionary])\n",
    "\n",
    " \n",
    "\n",
    "bigram_df = pd.DataFrame.from_dict(bigram_hip[0], orient='index').reset_index()\n",
    "bigram_df.columns = ['bigram','Count']\n",
    "\n",
    "bigram_sorted = bigram_df.sort_values(by=['Count'],ascending=False)\n",
    "\n",
    "bigram_sorted.head(20)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'bool' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-283-8fafc145dc53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create a way to remove all bigrams that are the same two words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbigram_sorted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bigram_same'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbigram_sorted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bigram'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3192\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3193\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3194\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'bool' object is not callable"
     ]
    }
   ],
   "source": [
    "# Create a way to remove all bigrams that are the same two words \n",
    "#bigram_sorted['bigram_same'] = bigram_sorted['bigram'].apply([0] == [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'bigram_same'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3077\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3078\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'bigram_same'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-280-39671c7699b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbigram_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mbigram_sorted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bigram_same'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbigram_sorted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bigram'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mbigram_sorted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bigram'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   4113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3078\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'bigram_same'"
     ]
    }
   ],
   "source": [
    "#for i in range(len(bigram_sorted)):\n",
    "#    bigram_sorted['bigram_same'] = [bigram_sorted['bigram'].apply([0] == [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
